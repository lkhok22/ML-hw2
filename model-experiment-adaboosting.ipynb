{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":14242,"databundleVersionId":568274,"sourceType":"competition"}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install dagshub mlflow","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T18:44:52.934663Z","iopub.execute_input":"2025-04-27T18:44:52.935034Z","iopub.status.idle":"2025-04-27T18:45:09.830941Z","shell.execute_reply.started":"2025-04-27T18:44:52.935007Z","shell.execute_reply":"2025-04-27T18:45:09.829918Z"}},"outputs":[{"name":"stdout","text":"Collecting dagshub\n  Downloading dagshub-0.5.9-py3-none-any.whl.metadata (12 kB)\nCollecting mlflow\n  Downloading mlflow-2.22.0-py3-none-any.whl.metadata (30 kB)\nRequirement already satisfied: PyYAML>=5 in /usr/local/lib/python3.11/dist-packages (from dagshub) (6.0.2)\nCollecting appdirs>=1.4.4 (from dagshub)\n  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\nRequirement already satisfied: click>=8.0.4 in /usr/local/lib/python3.11/dist-packages (from dagshub) (8.1.8)\nRequirement already satisfied: httpx>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from dagshub) (0.28.1)\nRequirement already satisfied: GitPython>=3.1.29 in /usr/local/lib/python3.11/dist-packages (from dagshub) (3.1.44)\nRequirement already satisfied: rich>=13.1.0 in /usr/local/lib/python3.11/dist-packages (from dagshub) (14.0.0)\nCollecting dacite~=1.6.0 (from dagshub)\n  Downloading dacite-1.6.0-py3-none-any.whl.metadata (14 kB)\nRequirement already satisfied: tenacity>=8.2.2 in /usr/local/lib/python3.11/dist-packages (from dagshub) (9.0.0)\nCollecting gql[requests] (from dagshub)\n  Downloading gql-3.5.2-py2.py3-none-any.whl.metadata (9.4 kB)\nRequirement already satisfied: dataclasses-json in /usr/local/lib/python3.11/dist-packages (from dagshub) (0.6.7)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from dagshub) (2.2.3)\nCollecting treelib>=1.6.4 (from dagshub)\n  Downloading treelib-1.7.1-py3-none-any.whl.metadata (1.4 kB)\nCollecting pathvalidate>=3.0.0 (from dagshub)\n  Downloading pathvalidate-3.2.3-py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: python-dateutil in /usr/local/lib/python3.11/dist-packages (from dagshub) (2.9.0.post0)\nRequirement already satisfied: boto3 in /usr/local/lib/python3.11/dist-packages (from dagshub) (1.37.29)\nRequirement already satisfied: semver in /usr/local/lib/python3.11/dist-packages (from dagshub) (3.0.4)\nCollecting dagshub-annotation-converter>=0.1.5 (from dagshub)\n  Downloading dagshub_annotation_converter-0.1.9-py3-none-any.whl.metadata (2.5 kB)\nCollecting mlflow-skinny==2.22.0 (from mlflow)\n  Downloading mlflow_skinny-2.22.0-py3-none-any.whl.metadata (31 kB)\nRequirement already satisfied: Flask<4 in /usr/local/lib/python3.11/dist-packages (from mlflow) (3.1.0)\nRequirement already satisfied: Jinja2<4,>=2.11 in /usr/local/lib/python3.11/dist-packages (from mlflow) (3.1.6)\nRequirement already satisfied: alembic!=1.10.0,<2 in /usr/local/lib/python3.11/dist-packages (from mlflow) (1.15.2)\nRequirement already satisfied: docker<8,>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from mlflow) (7.1.0)\nCollecting graphene<4 (from mlflow)\n  Downloading graphene-3.4.3-py2.py3-none-any.whl.metadata (6.9 kB)\nCollecting gunicorn<24 (from mlflow)\n  Downloading gunicorn-23.0.0-py3-none-any.whl.metadata (4.4 kB)\nRequirement already satisfied: markdown<4,>=3.3 in /usr/local/lib/python3.11/dist-packages (from mlflow) (3.7)\nRequirement already satisfied: matplotlib<4 in /usr/local/lib/python3.11/dist-packages (from mlflow) (3.7.5)\nRequirement already satisfied: numpy<3 in /usr/local/lib/python3.11/dist-packages (from mlflow) (1.26.4)\nRequirement already satisfied: pyarrow<20,>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from mlflow) (19.0.1)\nRequirement already satisfied: scikit-learn<2 in /usr/local/lib/python3.11/dist-packages (from mlflow) (1.2.2)\nRequirement already satisfied: scipy<2 in /usr/local/lib/python3.11/dist-packages (from mlflow) (1.15.2)\nRequirement already satisfied: sqlalchemy<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from mlflow) (2.0.38)\nRequirement already satisfied: cachetools<6,>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow) (5.5.2)\nRequirement already satisfied: cloudpickle<4 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow) (3.1.1)\nCollecting databricks-sdk<1,>=0.20.0 (from mlflow-skinny==2.22.0->mlflow)\n  Downloading databricks_sdk-0.50.0-py3-none-any.whl.metadata (38 kB)\nCollecting fastapi<1 (from mlflow-skinny==2.22.0->mlflow)\n  Downloading fastapi-0.115.12-py3-none-any.whl.metadata (27 kB)\nRequirement already satisfied: importlib_metadata!=4.7.0,<9,>=3.7.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow) (8.6.1)\nRequirement already satisfied: opentelemetry-api<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow) (1.16.0)\nRequirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow) (1.16.0)\nRequirement already satisfied: packaging<25 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow) (24.2)\nRequirement already satisfied: protobuf<7,>=3.12.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow) (3.20.3)\nRequirement already satisfied: pydantic<3,>=1.10.8 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow) (2.11.3)\nRequirement already satisfied: requests<3,>=2.17.3 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow) (2.32.3)\nRequirement already satisfied: sqlparse<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow) (0.5.3)\nRequirement already satisfied: typing-extensions<5,>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow) (4.13.1)\nCollecting uvicorn<1 (from mlflow-skinny==2.22.0->mlflow)\n  Downloading uvicorn-0.34.2-py3-none-any.whl.metadata (6.5 kB)\nRequirement already satisfied: Mako in /usr/local/lib/python3.11/dist-packages (from alembic!=1.10.0,<2->mlflow) (1.3.9)\nRequirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from dagshub-annotation-converter>=0.1.5->dagshub) (5.3.1)\nRequirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from dagshub-annotation-converter>=0.1.5->dagshub) (11.1.0)\nRequirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from docker<8,>=4.0.0->mlflow) (2.3.0)\nRequirement already satisfied: Werkzeug>=3.1 in /usr/local/lib/python3.11/dist-packages (from Flask<4->mlflow) (3.1.3)\nRequirement already satisfied: itsdangerous>=2.2 in /usr/local/lib/python3.11/dist-packages (from Flask<4->mlflow) (2.2.0)\nRequirement already satisfied: blinker>=1.9 in /usr/local/lib/python3.11/dist-packages (from Flask<4->mlflow) (1.9.0)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from GitPython>=3.1.29->dagshub) (4.0.12)\nCollecting graphql-core<3.3,>=3.1 (from graphene<4->mlflow)\n  Downloading graphql_core-3.2.6-py3-none-any.whl.metadata (11 kB)\nCollecting graphql-relay<3.3,>=3.1 (from graphene<4->mlflow)\n  Downloading graphql_relay-3.2.0-py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.23.0->dagshub) (3.7.1)\nRequirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.23.0->dagshub) (2025.1.31)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.23.0->dagshub) (1.0.7)\nRequirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.23.0->dagshub) (3.10)\nRequirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.23.0->dagshub) (0.14.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from Jinja2<4,>=2.11->mlflow) (3.0.2)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (1.3.1)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (4.56.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (1.4.8)\nRequirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (3.2.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<3->mlflow) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<3->mlflow) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<3->mlflow) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<3->mlflow) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<3->mlflow) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<3->mlflow) (2.4.1)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->dagshub) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->dagshub) (2025.2)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil->dagshub) (1.17.0)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=13.1.0->dagshub) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=13.1.0->dagshub) (2.19.1)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<2->mlflow) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<2->mlflow) (3.6.0)\nRequirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy<3,>=1.4.0->mlflow) (3.1.1)\nRequirement already satisfied: botocore<1.38.0,>=1.37.29 in /usr/local/lib/python3.11/dist-packages (from boto3->dagshub) (1.37.29)\nRequirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from boto3->dagshub) (1.0.1)\nRequirement already satisfied: s3transfer<0.12.0,>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from boto3->dagshub) (0.11.4)\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json->dagshub) (3.26.1)\nRequirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json->dagshub) (0.9.0)\nCollecting graphql-core<3.3,>=3.1 (from graphene<4->mlflow)\n  Downloading graphql_core-3.2.4-py3-none-any.whl.metadata (10 kB)\nRequirement already satisfied: yarl<2.0,>=1.6 in /usr/local/lib/python3.11/dist-packages (from gql[requests]->dagshub) (1.19.0)\nCollecting backoff<3.0,>=1.11.1 (from gql[requests]->dagshub)\n  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\nRequirement already satisfied: requests-toolbelt<2,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from gql[requests]->dagshub) (1.0.0)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.23.0->dagshub) (1.3.1)\nRequirement already satisfied: google-auth~=2.0 in /usr/local/lib/python3.11/dist-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==2.22.0->mlflow) (2.27.0)\nCollecting starlette<0.47.0,>=0.40.0 (from fastapi<1->mlflow-skinny==2.22.0->mlflow)\n  Downloading starlette-0.46.2-py3-none-any.whl.metadata (6.2 kB)\nRequirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->GitPython>=3.1.29->dagshub) (5.0.2)\nRequirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib_metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==2.22.0->mlflow) (3.21.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=13.1.0->dagshub) (0.1.2)\nRequirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.22.0->mlflow) (1.2.18)\nRequirement already satisfied: setuptools>=16.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.22.0->mlflow) (75.1.0)\nRequirement already satisfied: opentelemetry-semantic-conventions==0.37b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==2.22.0->mlflow) (0.37b0)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.10.8->mlflow-skinny==2.22.0->mlflow) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.10.8->mlflow-skinny==2.22.0->mlflow) (2.33.1)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.10.8->mlflow-skinny==2.22.0->mlflow) (0.4.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==2.22.0->mlflow) (3.4.1)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json->dagshub) (1.0.0)\nRequirement already satisfied: multidict>=4.0 in /usr/local/lib/python3.11/dist-packages (from yarl<2.0,>=1.6->gql[requests]->dagshub) (6.2.0)\nRequirement already satisfied: propcache>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from yarl<2.0,>=1.6->gql[requests]->dagshub) (0.3.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3->mlflow) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3->mlflow) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<3->mlflow) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<3->mlflow) (2024.2.0)\nRequirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.11/dist-packages (from deprecated>=1.2.6->opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.22.0->mlflow) (1.17.2)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.22.0->mlflow) (0.4.1)\nRequirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.22.0->mlflow) (4.9)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<3->mlflow) (2024.2.0)\nRequirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.22.0->mlflow) (0.6.1)\nDownloading dagshub-0.5.9-py3-none-any.whl (260 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m260.1/260.1 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading mlflow-2.22.0-py3-none-any.whl (29.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29.0/29.0 MB\u001b[0m \u001b[31m50.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading mlflow_skinny-2.22.0-py3-none-any.whl (6.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m82.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\nDownloading dacite-1.6.0-py3-none-any.whl (12 kB)\nDownloading dagshub_annotation_converter-0.1.9-py3-none-any.whl (33 kB)\nDownloading graphene-3.4.3-py2.py3-none-any.whl (114 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.9/114.9 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading gunicorn-23.0.0-py3-none-any.whl (85 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.0/85.0 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pathvalidate-3.2.3-py3-none-any.whl (24 kB)\nDownloading treelib-1.7.1-py3-none-any.whl (19 kB)\nDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\nDownloading databricks_sdk-0.50.0-py3-none-any.whl (692 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m692.3/692.3 kB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading fastapi-0.115.12-py3-none-any.whl (95 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading graphql_core-3.2.4-py3-none-any.whl (203 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.2/203.2 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading graphql_relay-3.2.0-py3-none-any.whl (16 kB)\nDownloading uvicorn-0.34.2-py3-none-any.whl (62 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading gql-3.5.2-py2.py3-none-any.whl (74 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.3/74.3 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading starlette-0.46.2-py3-none-any.whl (72 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: appdirs, uvicorn, treelib, pathvalidate, gunicorn, graphql-core, dacite, backoff, starlette, graphql-relay, gql, graphene, fastapi, databricks-sdk, mlflow-skinny, dagshub-annotation-converter, mlflow, dagshub\n  Attempting uninstall: dacite\n    Found existing installation: dacite 1.9.2\n    Uninstalling dacite-1.9.2:\n      Successfully uninstalled dacite-1.9.2\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nydata-profiling 4.16.1 requires dacite>=1.8, but you have dacite 1.6.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed appdirs-1.4.4 backoff-2.2.1 dacite-1.6.0 dagshub-0.5.9 dagshub-annotation-converter-0.1.9 databricks-sdk-0.50.0 fastapi-0.115.12 gql-3.5.2 graphene-3.4.3 graphql-core-3.2.4 graphql-relay-3.2.0 gunicorn-23.0.0 mlflow-2.22.0 mlflow-skinny-2.22.0 pathvalidate-3.2.3 starlette-0.46.2 treelib-1.7.1 uvicorn-0.34.2\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import dagshub\ndagshub.init(repo_owner='lkhok22', repo_name='ML-hw2', mlflow=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T18:45:09.832366Z","iopub.execute_input":"2025-04-27T18:45:09.832767Z","iopub.status.idle":"2025-04-27T18:45:43.643244Z","shell.execute_reply.started":"2025-04-27T18:45:09.832725Z","shell.execute_reply":"2025-04-27T18:45:43.642004Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"                                       \u001b[1m❗❗❗ AUTHORIZATION REQUIRED ❗❗❗\u001b[0m                                        \n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">                                       <span style=\"font-weight: bold\">❗❗❗ AUTHORIZATION REQUIRED ❗❗❗</span>                                        \n</pre>\n"},"metadata":{}},{"name":"stdout","text":"\n\nOpen the following link in your browser to authorize the client:\nhttps://dagshub.com/login/oauth/authorize?state=f164c705-4b0c-4314-866f-c397e5ddc9c5&client_id=32b60ba385aa7cecf24046d8195a71c07dd345d9657977863b52e7748e0f0f28&middleman_request_id=9886277ae74fcdffe6dff140a9032b60abeadc878d67fdd1658558e16c514d29\n\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Output()","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Accessing as lkhok22\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Accessing as lkhok22\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Initialized MLflow to track repo \u001b[32m\"lkhok22/ML-hw2\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"lkhok22/ML-hw2\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Repository lkhok22/ML-hw2 initialized!\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository lkhok22/ML-hw2 initialized!\n</pre>\n"},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-27T18:45:43.646574Z","iopub.execute_input":"2025-04-27T18:45:43.647153Z","iopub.status.idle":"2025-04-27T18:45:44.117740Z","shell.execute_reply.started":"2025-04-27T18:45:43.647123Z","shell.execute_reply":"2025-04-27T18:45:44.116516Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/ieee-fraud-detection/sample_submission.csv\n/kaggle/input/ieee-fraud-detection/test_identity.csv\n/kaggle/input/ieee-fraud-detection/train_identity.csv\n/kaggle/input/ieee-fraud-detection/test_transaction.csv\n/kaggle/input/ieee-fraud-detection/train_transaction.csv\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"pd.set_option('display.max_columns', None)  \npd.set_option('display.width', None)        \npd.set_option('display.expand_frame_repr', False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T18:45:44.119001Z","iopub.execute_input":"2025-04-27T18:45:44.119406Z","iopub.status.idle":"2025-04-27T18:45:44.124158Z","shell.execute_reply.started":"2025-04-27T18:45:44.119382Z","shell.execute_reply":"2025-04-27T18:45:44.123084Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"# Read and merge, Reduce memory","metadata":{}},{"cell_type":"code","source":"df_train_id = pd.read_csv('/kaggle/input/ieee-fraud-detection/train_identity.csv')\ndf_train_tr = pd.read_csv('/kaggle/input/ieee-fraud-detection/train_transaction.csv')\ndf_test_id = pd.read_csv('/kaggle/input/ieee-fraud-detection/test_identity.csv')\ndf_test_tr = pd.read_csv('/kaggle/input/ieee-fraud-detection/test_transaction.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T18:45:44.125264Z","iopub.execute_input":"2025-04-27T18:45:44.125649Z","iopub.status.idle":"2025-04-27T18:46:45.514872Z","shell.execute_reply.started":"2025-04-27T18:45:44.125613Z","shell.execute_reply":"2025-04-27T18:46:45.513741Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"def reduce_mem_usage(df):\n    \"\"\" iterate through all the columns of a dataframe and modify the data type\n        to reduce memory usage.        \n    \"\"\"\n    start_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n    \n    for col in df.columns:\n        col_type = df[col].dtype\n        \n        if col_type != object:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n        \n\n    end_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n    \n    return df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T18:46:45.516319Z","iopub.execute_input":"2025-04-27T18:46:45.517280Z","iopub.status.idle":"2025-04-27T18:46:45.527217Z","shell.execute_reply.started":"2025-04-27T18:46:45.517246Z","shell.execute_reply":"2025-04-27T18:46:45.526234Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"df_train = pd.merge(df_train_tr, df_train_id, on='TransactionID', how='left')\ndf_test = pd.merge(df_test_tr, df_test_id, on='TransactionID', how='left')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T18:46:45.528264Z","iopub.execute_input":"2025-04-27T18:46:45.528604Z","iopub.status.idle":"2025-04-27T18:46:47.409435Z","shell.execute_reply.started":"2025-04-27T18:46:45.528566Z","shell.execute_reply":"2025-04-27T18:46:47.408413Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"del df_train_id, df_train_tr\ndel df_test_id,df_test_tr","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T18:46:47.410367Z","iopub.execute_input":"2025-04-27T18:46:47.410619Z","iopub.status.idle":"2025-04-27T18:46:47.475640Z","shell.execute_reply.started":"2025-04-27T18:46:47.410589Z","shell.execute_reply":"2025-04-27T18:46:47.474826Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"train = reduce_mem_usage(df_train)\ntest = reduce_mem_usage(df_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T18:46:47.478508Z","iopub.execute_input":"2025-04-27T18:46:47.478796Z","iopub.status.idle":"2025-04-27T18:46:53.151879Z","shell.execute_reply.started":"2025-04-27T18:46:47.478774Z","shell.execute_reply":"2025-04-27T18:46:53.150809Z"}},"outputs":[{"name":"stdout","text":"Memory usage of dataframe is 1955.37 MB\nMemory usage after optimization is: 645.97 MB\nDecreased by 67.0%\nMemory usage of dataframe is 1673.87 MB\nMemory usage after optimization is: 561.50 MB\nDecreased by 66.5%\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"D_features = ['D4','D6','D11','D12','D14','D15']\nsum = 0\nfor i in D_features:\n  filt = train[train[i]<0.0].index\n  \n  for j in filt:\n    train=train.drop(index=j)\n\n\ntrain.drop([\"M1\"], axis=1, inplace=True)\ntest.drop([\"M1\"], axis=1, inplace=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T18:46:53.152968Z","iopub.execute_input":"2025-04-27T18:46:53.153242Z","iopub.status.idle":"2025-04-27T18:47:21.403281Z","shell.execute_reply.started":"2025-04-27T18:46:53.153218Z","shell.execute_reply":"2025-04-27T18:47:21.402201Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"X=df_train.drop(columns=['isFraud'])\ny=df_train['isFraud']\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T18:47:21.404373Z","iopub.execute_input":"2025-04-27T18:47:21.404656Z","iopub.status.idle":"2025-04-27T18:47:22.313424Z","shell.execute_reply.started":"2025-04-27T18:47:21.404631Z","shell.execute_reply":"2025-04-27T18:47:22.312421Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n#80% train, 20% test\n\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=42\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T18:47:22.314433Z","iopub.execute_input":"2025-04-27T18:47:22.314696Z","iopub.status.idle":"2025-04-27T18:47:25.781413Z","shell.execute_reply.started":"2025-04-27T18:47:22.314673Z","shell.execute_reply":"2025-04-27T18:47:25.780425Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"train_ids = X_train.pop('TransactionID')\ntest_ids = X_test.pop('TransactionID')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T18:47:25.782363Z","iopub.execute_input":"2025-04-27T18:47:25.783060Z","iopub.status.idle":"2025-04-27T18:47:25.796129Z","shell.execute_reply.started":"2025-04-27T18:47:25.783026Z","shell.execute_reply":"2025-04-27T18:47:25.794993Z"}},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":"# Cleaning","metadata":{}},{"cell_type":"code","source":"from sklearn.base import BaseEstimator, TransformerMixin\nclass DropNullColumns(BaseEstimator, TransformerMixin):\n    def __init__(self, threshold=0.7):\n        self.threshold = threshold\n        self.columns_to_drop_ = []\n\n    def fit(self, X, y=None):\n        null_ratios = X.isna().mean()\n        self.columns_to_drop_ = null_ratios[null_ratios > self.threshold].index.tolist()\n        return self\n\n    def transform(self, X):\n        return X.drop(columns=self.columns_to_drop_, errors='ignore')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T18:47:25.797401Z","iopub.execute_input":"2025-04-27T18:47:25.797744Z","iopub.status.idle":"2025-04-27T18:47:25.819339Z","shell.execute_reply.started":"2025-04-27T18:47:25.797703Z","shell.execute_reply":"2025-04-27T18:47:25.818369Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"# class ReplaceNulls(BaseEstimator, TransformerMixin):\n#     def fit(self, X, y=None):\n#         return self\n\n#     def transform(self, X):\n#         df = X.copy()\n#         numeric_cols = df.select_dtypes(include=['number']).columns\n#         categoric_cols = df.select_dtypes(include=['object', 'category']).columns\n#         df[numeric_cols] = df[numeric_cols].fillna(-999)\n#         df[categoric_cols] = df[categoric_cols].fillna(\"NAN\")\n#         return df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T18:47:25.820359Z","iopub.execute_input":"2025-04-27T18:47:25.820699Z","iopub.status.idle":"2025-04-27T18:47:25.843707Z","shell.execute_reply.started":"2025-04-27T18:47:25.820667Z","shell.execute_reply":"2025-04-27T18:47:25.842620Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"from sklearn.base import BaseEstimator, TransformerMixin\nimport pandas as pd\n\nclass FillMissingValues(BaseEstimator, TransformerMixin):\n    def __init__(self, strategy_num='mean', strategy_cat='mode'):\n        self.strategy_num = strategy_num\n        self.strategy_cat = strategy_cat\n        self.num_fill_values_ = {}\n        self.cat_fill_values_ = {}\n\n    def fit(self, X, y=None):\n        num_cols = X.select_dtypes(include=['float64', 'int64']).columns\n        cat_cols = X.select_dtypes(include=['object', 'category']).columns\n\n        for col in num_cols:\n            if self.strategy_num == 'mean':\n                self.num_fill_values_[col] = X[col].mean()\n            elif self.strategy_num == 'median':\n                self.num_fill_values_[col] = X[col].median()\n\n        for col in cat_cols:\n            if self.strategy_cat == 'mode':\n                self.cat_fill_values_[col] = X[col].mode()[0]\n\n        return self\n\n    def transform(self, X):\n        X_filled = X.copy()\n        for col, fill_value in self.num_fill_values_.items():\n            X_filled[col] = X_filled[col].fillna(fill_value)\n        for col, fill_value in self.cat_fill_values_.items():\n            X_filled[col] = X_filled[col].fillna(fill_value)\n        return X_filled\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T18:47:25.844946Z","iopub.execute_input":"2025-04-27T18:47:25.845258Z","iopub.status.idle":"2025-04-27T18:47:25.865298Z","shell.execute_reply.started":"2025-04-27T18:47:25.845236Z","shell.execute_reply":"2025-04-27T18:47:25.864236Z"}},"outputs":[],"execution_count":16},{"cell_type":"markdown","source":"# Feature Engineering","metadata":{}},{"cell_type":"code","source":"# class CustomPreprocessor(BaseEstimator, TransformerMixin):\n#     def __init__(self, threshold_for_woe=3):\n#         self.threshold = threshold_for_woe\n\n#     def fit(self, X, y):\n#         self.woe_columns_ = []\n#         self.one_hot_columns_ = []\n\n#         s = X.select_dtypes(include=['object', 'category']).nunique()\n#         self.woe_columns_ = s[s > self.threshold].index.tolist()\n#         self.one_hot_columns_ = s[s <= self.threshold].index.tolist()\n\n#         df = X.copy()\n#         df['target'] = y\n\n#         self.woe_mappings_ = {}\n\n#         for col in self.woe_columns_:\n#             grouped = df.groupby(col)['target'].agg(['count', 'sum'])\n#             grouped.columns = ['n_obs', 'n_pos']\n#             grouped['n_neg'] = grouped['n_obs'] - grouped['n_pos']\n#             eps = 1e-6  # small number to avoid division by zero\n#             grouped['prop_pos'] = grouped['n_pos'] / max(grouped['n_pos'].sum(), eps)\n#             grouped['prop_neg'] = grouped['n_neg'] / max(grouped['n_neg'].sum(), eps)\n#             grouped['woe'] = np.log((grouped['prop_pos'] + eps) / (grouped['prop_neg'] + eps))\n\n#             self.woe_mappings_[col] = grouped['woe'].fillna(0).to_dict()\n#         return self\n\n#     def transform(self, X):\n#         df = X.copy()\n\n#         for col in self.woe_columns_:\n#             df[f\"{col}_woe\"] = df[col].map(self.woe_mappings_[col])\n#             df.drop(columns=col, inplace=True)\n\n#         df = pd.get_dummies(df, columns=self.one_hot_columns_, drop_first=True)\n#         return df\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T18:47:25.866433Z","iopub.execute_input":"2025-04-27T18:47:25.866731Z","iopub.status.idle":"2025-04-27T18:47:25.889616Z","shell.execute_reply.started":"2025-04-27T18:47:25.866700Z","shell.execute_reply":"2025-04-27T18:47:25.888436Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"from sklearn.base import BaseEstimator, TransformerMixin\nfrom sklearn.preprocessing import LabelEncoder\n\nclass LabelEncodeCategoricals(BaseEstimator, TransformerMixin):\n    def __init__(self):\n        self.encoders = {}\n\n    def fit(self, X, y=None):\n        cat_cols = X.select_dtypes(include=['object', 'category']).columns\n        for col in cat_cols:\n            le = LabelEncoder()\n            X_col = X[col].astype(str).fillna('NA')\n            le.fit(X_col)\n            self.encoders[col] = le\n        return self\n\n    def transform(self, X):\n        X_encoded = X.copy()\n        for col, le in self.encoders.items():\n            X_encoded[col] = le.transform(X_encoded[col].astype(str).fillna('NA'))\n        return X_encoded\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T18:47:25.890730Z","iopub.execute_input":"2025-04-27T18:47:25.891025Z","iopub.status.idle":"2025-04-27T18:47:25.914030Z","shell.execute_reply.started":"2025-04-27T18:47:25.891002Z","shell.execute_reply":"2025-04-27T18:47:25.912810Z"}},"outputs":[],"execution_count":18},{"cell_type":"markdown","source":"# Feature Selection","metadata":{}},{"cell_type":"code","source":"# class CorrelationFilter(BaseEstimator, TransformerMixin):\n#     def fit(self, X, y):\n#         df = X.copy()\n#         df['target'] = y\n#         corr_matrix = df.corr().abs()\n#         mask = np.triu(np.ones(corr_matrix.shape), k=1).astype(bool)\n#         corr_pairs = pd.DataFrame(corr_matrix.where(mask).stack(), columns=[\"correlation\"]).reset_index()\n#         corr_pairs.columns = ['feature1', 'feature2', 'correlation']\n\n#         target_corr = X.corrwith(y).abs()\n#         self.to_drop_ = []\n\n#         for _, row in corr_pairs[corr_pairs['correlation'] > 0.8].iterrows():\n#             f1, f2 = row['feature1'], row['feature2']\n#             drop = f1 if target_corr[f1] < target_corr[f2] else f2\n#             self.to_drop_.append(drop)\n\n#         self.to_drop_ = list(set(self.to_drop_))\n#         return self\n\n#     def transform(self, X):\n#         return X.drop(columns=[col for col in self.to_drop_ if col in X.columns], errors='ignore')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T18:47:25.915194Z","iopub.execute_input":"2025-04-27T18:47:25.915614Z","iopub.status.idle":"2025-04-27T18:47:25.939837Z","shell.execute_reply.started":"2025-04-27T18:47:25.915581Z","shell.execute_reply":"2025-04-27T18:47:25.938594Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"class FeatureSelectorByImportance(BaseEstimator, TransformerMixin):\n    def __init__(self, model, percentile=30):\n        self.model = model\n        self.percentile = percentile\n\n    def fit(self, X, y):\n        self.model.fit(X, y)\n        importances = self.model.feature_importances_\n        threshold = np.percentile(importances, 100 - self.percentile)\n\n        # If X is a DataFrame, use column names, otherwise make generic names\n        if hasattr(X, 'columns'):\n            self.feature_names_ = X.columns\n        else:\n            self.feature_names_ = [f\"feature_{i}\" for i in range(X.shape[1])]\n\n        self.selected_features_ = np.array(self.feature_names_)[importances >= threshold]\n        return self\n\n    def transform(self, X):\n        # Same: if X is DataFrame, use columns, else use indices\n        if hasattr(X, 'loc'):\n            return X.loc[:, self.selected_features_]\n        else:\n            selected_indices = [i for i, name in enumerate(self.feature_names_) if name in self.selected_features_]\n            return X[:, selected_indices]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T18:56:46.942461Z","iopub.execute_input":"2025-04-27T18:56:46.943223Z","iopub.status.idle":"2025-04-27T18:56:46.951492Z","shell.execute_reply.started":"2025-04-27T18:56:46.943189Z","shell.execute_reply":"2025-04-27T18:56:46.950137Z"}},"outputs":[],"execution_count":28},{"cell_type":"markdown","source":"# Training and Evaluation","metadata":{}},{"cell_type":"code","source":"import mlflow\nimport mlflow.sklearn\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer, make_column_selector\nfrom sklearn.preprocessing import OrdinalEncoder\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import roc_auc_score\n\n# Set experiment\nmlflow.set_experiment(\"AdaBoost\")\n\n# Preprocessor: handles NaNs FIRST\npreprocessor = ColumnTransformer(transformers=[\n    ('num', SimpleImputer(strategy='median'), make_column_selector(dtype_include=['int64', 'float64'])),\n    ('cat', Pipeline(steps=[\n        ('imputer', SimpleImputer(strategy='most_frequent')),\n        ('encoder', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1))\n    ]), make_column_selector(dtype_include=['object', 'category']))\n])\n\n# Full pipeline\npipeline = Pipeline([\n    ('drop_nulls', DropNullColumns(threshold=0.9)),  # drop columns with too many nulls\n    ('preprocessing', preprocessor),                # THEN impute + encode\n    ('feature_selection', FeatureSelectorByImportance( # THEN select features\n        model=DecisionTreeClassifier(max_depth=5, random_state=42),\n        percentile=30\n    )),\n    ('model', AdaBoostClassifier(                     # THEN model\n        base_estimator=DecisionTreeClassifier(max_depth=5),\n        n_estimators=100,\n        learning_rate=0.5,\n        random_state=42\n    ))\n])\n\n# MLflow logging\nwith mlflow.start_run(run_name=\"AdaBoost2\"):\n\n    # Fit\n    pipeline.fit(X_train, y_train)\n\n    # Predict\n    train_preds = pipeline.predict_proba(X_train)[:, 1]\n    test_preds = pipeline.predict_proba(X_test)[:, 1]\n\n    # Score\n    train_auc = roc_auc_score(y_train, train_preds)\n    test_auc = roc_auc_score(y_test, test_preds)\n\n    # Log params\n    mlflow.log_param(\"model\", \"AdaBoost\")\n    mlflow.log_param(\"n_estimators\", 100)\n    mlflow.log_param(\"learning_rate\", 0.5)\n    mlflow.log_param(\"random_state\", 42)\n\n    # Log metrics\n    mlflow.log_metric(\"train_auc\", train_auc)\n    mlflow.log_metric(\"test_auc\", test_auc)\n\n    # Log model\n    mlflow.sklearn.log_model(pipeline, \"adaboost_full_pipeline\")\n\n    print(f\"Train AUC: {train_auc:.4f}\")\n    print(f\"Test AUC: {test_auc:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T18:56:54.078830Z","iopub.execute_input":"2025-04-27T18:56:54.079221Z","iopub.status.idle":"2025-04-27T18:58:31.764406Z","shell.execute_reply.started":"2025-04-27T18:56:54.079195Z","shell.execute_reply":"2025-04-27T18:58:31.763387Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n  warnings.warn(\n\u001b[31m2025/04/27 18:58:29 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"Train AUC: 0.8207\nTest AUC: 0.8044\n🏃 View run AdaBoost2 at: https://dagshub.com/lkhok22/ML-hw2.mlflow/#/experiments/7/runs/fbd411cf6bd1465bac1c8a7ce7e7264a\n🧪 View experiment at: https://dagshub.com/lkhok22/ML-hw2.mlflow/#/experiments/7\n","output_type":"stream"}],"execution_count":29},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}