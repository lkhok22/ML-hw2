# ML-hw2

------------------------პროექტის მიმოხილვა------------------
IEEE-CIS Fraud Detection არის kaggle-ის კონკურსი, რომლის მიზანია განისაზღვროს, არის თუ არა ონლაინ ტრანზაქცია გაყალბებული (isFraud ცვლადი) ტრანზაქციის მონაცემების მიხედვით.
მონაცემები გაყოფილია ორ ფაილად: identity და transaction, რომლებიც დაკავშირებულია TransactionID-ის მიხედვით. რისი გაერთიანებაც ჩვენით მოგვიწევს. ეს ფაილები მოიცავს როგორც რიცხვით,
ასევე კატეგორიულ ცვლადებსაც.


------------------------ჩემი მიდგომა------------------------
ჩემი მიდგომა იყო რომ დამეწყო რაც შეიძლება მარტივად და დრო და დრო გამეუმჯობესებინა მიდგომა, ამიტომ თავდაპირველად დავიწყე logistic regression-ით.
რაც შეეხება train-ის დაყოფას, თავიდან 70 10 20 (train validation test) დავყავი, მაგრამ საბოლოოდ ვალიდაციის გამოყენება ამხელა ცხრილზე დიდ დროს წაიღებდა და საჭიროდ აღარ ჩავთვალე და
სტანდარტულად 80 20 დავყავი.
# LOGISTIC REGRESSION
-cleaning
რადგანაც ამ მოდელს არ შეუძლია Null ცვლადების დამუშავება, ამიტომ ჯერ დავიწყე ყველაზე მარტივად რიცხვითების -999-ებით 
(ეს უკეთესია ვიდრე 0, იმიტომ რომ შეიძლება 0-ს ისედაც ქონდეს რაღაცა დანიშნულება და -999 უფრო უმნიშვნელოდ იქნება) ჩანაცვლებით და კატეგორიულში nan-ებით.
ამავდროულად დავდროპე 80%ზე მეტი null-ების შემცველი სვეტები. 

-feature engineering
მოცემული ფაილის გადახედვის შემდეგ შევნიშნე რომ უმეტესობა კატეგორიულ ცვლადს დიდი რაოდენობის განსხვავებული მონაცემები ქონდა, ამიტომ მხოლოდ one hot encodig
არ გამოდგებოდა რადგან საკმაოდ დიდი გახდებოდა ცხრილი. აამიტომ სემინარის მსგავსაც woe და one hot გავაერთიანე და 3 ზე მეტი განსხვავებულის შემდეგ woe ენკოდინგს ვუშვებდი.

-feature selection
ისეთ მონაცემებზე რომელიცაა V--- ან C--- (ან მსგავსი მონაცემებირომლების კონკრეტული დანიშულება ჩვენთვის უცნობია და უბრალოდ ბევრია) 
მონაცემების ერთმანეთთან კორელაციის heat map-ის და არამარტო(ნებისმიერი სხვა პლოტებითაც გამოჩნდებოდა) ნახაზებიდან კარგად ჩანს რამდენად დიდი რაოდენობაა ერთმანეთთან
მჭიდროდ კორელირებული და შესაბამისად ჩვენთვის არაფერი ახალის მომცემი. ამიტომ გადავწყვიტე კორელაციით ზედმეტი სვეტების დადროპვა.

და საბოლოოდ გავუშვი Logistic regressionze. ამავე მოდელზე ცვლილებებად მქონდა scaler-ის დამატება, რამაც ბევრად უკეთესი შედეგი დადო, და ასევე null-ების mean-ით და მოდათი ჩანაცვლებაც ვცადე, რამაც საბოლოოდ უარესი შედეგი მომცა.


# RANDOM FOREST

აქაც Logistic-ის მსგავად გავუშვი preprocessing თავიდან, მაგრამ რატომღაც auc score-ს 1-ს ვიღებდი ანუ რაღაც leak მქონდა, რაც ვერ გავასწორე, მაგრამ გადავწყვიტე რომ woe და one hot ხეებში ისედაც ზედმეტია, ამიტომ გამოვიყენე label encoding, და selection-ისთვის დავწერე ფუნქცია FeatureSelectorByImportance, რომელიც რამდენად მნიშვნელოვანია მაგის მიხედვით დროპავს ნაკლებად გამოსადეგ მონაცემების შემცველ სვეტებს.
ამან არც თუ ისე ცუდი შედეგი დადო, მაგრამ ჯერ ჯერობით Logistic-is საუკეთესო შედეგი სჯობნიდა.

# XGBOOSTING

აქაც წინას მსგავსად დავიწყე One hot და woe და შემდეგ კორელაციით გატესტვა, რომელმაც ცხადია ბევრად უკეთესი შედეგი დადო ვიდრე წინა ყველა ცდამ, შემდეგ null-ების სხვანაირად ჩანაცვლება ვცადე და მაგან დიდი სხვაობა არ მომცა, train-ზე თითქმის იგივე ქულა დაწერა, მაგრამ test-ზე შედარებით უკეთესი. შემდეგ random forest-ის მსგავსად აქაც შევცვალე woe და one hot label encoding-ით, ასევე კორელაციასთან ერთად FeatureSelectorByImportance ჩავამატე. საბოლოოდ სწორედ ეს აღმოჩნდებოდა საუკეთესო შედეგი.

# ADABOOST

იგივე რაც random forest-ზე, მაგრამ აქ leak არ მომხდარა და უკეთესი შედეგებიც მიიღო. მაგრამ ყველაზე დიდი დრო ამის დატრენინგებას სჭირდებოდა.

# GRADIENTBOOSTING

ამ მოდელისგან კარგ შედეგს ველოდებოდი, რადგან წინა დავალებაში საუკეთესო შედეგი ამან დადო, მაგრამ ამჯერად ერთ-ერთი ყველაზე დაბალი ქულა დადო woe one hot და კორელაციით. რაც ისედაც მისახვედრი იყო, რადგან არ არის ეგ პრეპროცესინგი ოპტიმალური ამ მოდელისთვის. და მართლაც სხვა სწორი მიდგომით შედეგმაც საკმაოდ აიწია და მისაღები ქულა დაწერა.


საბოლოოდ საუკეთესო შედეგი XGBoost-ს ქონდა.
MLFlow-ს ლინკი: https://dagshub.com/lkhok22/ML-hw2.mlflow/#/experiments/4?searchFilter=&orderByKey=attributes.start_time&orderByAsc=false&startTime=ALL&lifecycleFilter=Active&modelVersionFilter=All+Runs&datasetsFilter=W10%3D
